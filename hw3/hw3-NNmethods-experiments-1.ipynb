{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Эксперименты\n",
    "Здесь происходит идейно то же самое, но с вариациями в параметрах, описанных в статье. За все комбинации меня колаб забанит, поэтому приведу некоторые"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что от нас хотят в статье?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "u3wugeOHW-AV",
    "outputId": "7979e6ad-bff3-4493-c0e7-a9666383f9ae"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9XIrxSmW-AX"
   },
   "source": [
    "# Скачиваем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23476</th>\n",
       "      <td>McPain: John McCain Furious That Iran Treated ...</td>\n",
       "      <td>21st Century Wire says As 21WIRE reported earl...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 16, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23477</th>\n",
       "      <td>JUSTICE? Yahoo Settles E-mail Privacy Class-ac...</td>\n",
       "      <td>21st Century Wire says It s a familiar theme. ...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 16, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23478</th>\n",
       "      <td>Sunnistan: US and Allied ‘Safe Zone’ Plan to T...</td>\n",
       "      <td>Patrick Henningsen  21st Century WireRemember ...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 15, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23479</th>\n",
       "      <td>How to Blow $700 Million: Al Jazeera America F...</td>\n",
       "      <td>21st Century Wire says Al Jazeera America will...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 14, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23480</th>\n",
       "      <td>10 U.S. Navy Sailors Held by Iranian Military ...</td>\n",
       "      <td>21st Century Wire says As 21WIRE predicted in ...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 12, 2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23481 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0       Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1       Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2       Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3       Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4       Pope Francis Just Called Out Donald Trump Dur...   \n",
       "...                                                  ...   \n",
       "23476  McPain: John McCain Furious That Iran Treated ...   \n",
       "23477  JUSTICE? Yahoo Settles E-mail Privacy Class-ac...   \n",
       "23478  Sunnistan: US and Allied ‘Safe Zone’ Plan to T...   \n",
       "23479  How to Blow $700 Million: Al Jazeera America F...   \n",
       "23480  10 U.S. Navy Sailors Held by Iranian Military ...   \n",
       "\n",
       "                                                    text      subject  \\\n",
       "0      Donald Trump just couldn t wish all Americans ...         News   \n",
       "1      House Intelligence Committee Chairman Devin Nu...         News   \n",
       "2      On Friday, it was revealed that former Milwauk...         News   \n",
       "3      On Christmas day, Donald Trump announced that ...         News   \n",
       "4      Pope Francis used his annual Christmas Day mes...         News   \n",
       "...                                                  ...          ...   \n",
       "23476  21st Century Wire says As 21WIRE reported earl...  Middle-east   \n",
       "23477  21st Century Wire says It s a familiar theme. ...  Middle-east   \n",
       "23478  Patrick Henningsen  21st Century WireRemember ...  Middle-east   \n",
       "23479  21st Century Wire says Al Jazeera America will...  Middle-east   \n",
       "23480  21st Century Wire says As 21WIRE predicted in ...  Middle-east   \n",
       "\n",
       "                    date  \n",
       "0      December 31, 2017  \n",
       "1      December 31, 2017  \n",
       "2      December 30, 2017  \n",
       "3      December 29, 2017  \n",
       "4      December 25, 2017  \n",
       "...                  ...  \n",
       "23476   January 16, 2016  \n",
       "23477   January 16, 2016  \n",
       "23478   January 15, 2016  \n",
       "23479   January 14, 2016  \n",
       "23480   January 12, 2016  \n",
       "\n",
       "[23481 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('Fake.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfHbifWIW-Al"
   },
   "source": [
    "# Предобученные эмбеддинги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "M0lwyZUFW-Ap"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QQpX51Y4W-Aq"
   },
   "outputs": [],
   "source": [
    "# потом можете добавить свою предобработку\n",
    "\n",
    "def process_text(text):\n",
    "    \n",
    "    words = wordpunct_tokenize(text.lower())\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "HyI2erCDW-Ar",
    "outputId": "0e1fe01d-03f8-4073-b646-53f1a0834d90"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 23481/23481 [00:06<00:00, 3656.98it/s]\n"
     ]
    }
   ],
   "source": [
    "word2freq = {}\n",
    "lengths = []\n",
    "\n",
    "for text in tqdm(data.text):\n",
    "    \n",
    "    words = process_text(text)\n",
    "    \n",
    "    lengths.append(len(words))\n",
    "    \n",
    "    for word in words:\n",
    "        \n",
    "        if word in word2freq:\n",
    "            word2freq[word] += 1\n",
    "        else:\n",
    "            word2freq[word] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZbOg0FqW-A1"
   },
   "source": [
    "# Читаем файл с эмбеддингами\n",
    "### Этот файл с 300 числами для 2 000 000 слов и он может не влезть в память\n",
    "Поэтому прочитаем только те слова, которые мы знаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 95413/95413 [00:01<00:00, 51181.70it/s]\n"
     ]
    }
   ],
   "source": [
    "word2index = {'PAD': 0, 'UNK': 1}\n",
    "vectors = []\n",
    "\n",
    "n_words, embedding_dim = len(model.index_to_key), model.vector_size\n",
    "\n",
    "#паддинги и уникальные\n",
    "vectors.append(np.random.uniform(-0.25, 0.25, embedding_dim))\n",
    "vectors.append(np.random.uniform(-0.25, 0.25, embedding_dim))\n",
    "#progress_bar = tqdm(desc='Read word2vec', total=n_words)\n",
    "\n",
    "for word in tqdm(word2freq.keys()):\n",
    "    word2index[word] = len(word2index)\n",
    "    if word in model:\n",
    "        vectors.append(model.get_vector(word))\n",
    "    else:\n",
    "        vectors.append(np.random.uniform(-0.25, 0.25, embedding_dim))\n",
    "\n",
    "vectors = torch.FloatTensor(np.array(vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "_fo1fB6JW-A-"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "jaMMD5CDW-BG"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stBQ3yhqW-Bi"
   },
   "source": [
    "# Подготовим данные в DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "vPX_m5M4W-Bi"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "iHeFzZe1W-Bl"
   },
   "outputs": [],
   "source": [
    "cat_mapper = {sub: n for n, sub in enumerate(data.subject.unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "X3x9QhXYW-Bn",
    "outputId": "0a4dff58-d739-4847-f818-c3e0d321e78a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'News': 0,\n",
       " 'politics': 1,\n",
       " 'Government News': 2,\n",
       " 'left-news': 3,\n",
       " 'US_News': 4,\n",
       " 'Middle-east': 5}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ef--8SWbW-Bo"
   },
   "outputs": [],
   "source": [
    "data.subject = data.subject.map(cat_mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vc48ALg_W-Bp"
   },
   "source": [
    "# Читалка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ZkX8SC_sW-Bp"
   },
   "outputs": [],
   "source": [
    "class WordData(Dataset):\n",
    "    \n",
    "    def __init__(self, x_data, y_data, word2index, sequence_length=512, pad_token='PAD', verbose=True):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.x_data = []\n",
    "        self.y_data = y_data\n",
    "        \n",
    "        self.word2index = word2index\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        self.pad_token = pad_token\n",
    "        self.pad_index = self.word2index[self.pad_token]\n",
    "        \n",
    "        self.load(x_data, verbose=verbose)\n",
    "        \n",
    "    @staticmethod\n",
    "    def process_text(text):\n",
    "        \n",
    "        # Место для вашей предобработки\n",
    "        \n",
    "        words = wordpunct_tokenize(text.lower())\n",
    "        #words = re.findall('[a-яА-ЯеЁ]+', text.lower())\n",
    "        return words\n",
    "        \n",
    "    def load(self, data, verbose=True):\n",
    "        \n",
    "        data_iterator = tqdm(data, desc='Loading data', disable=not verbose)\n",
    "        \n",
    "        for text in data_iterator:\n",
    "            \n",
    "            words = self.process_text(text)\n",
    "            \n",
    "            indexed_words = self.indexing(words)\n",
    "            \n",
    "            self.x_data.append(indexed_words)\n",
    "    \n",
    "    def indexing(self, tokenized_text):\n",
    "\n",
    "        # здесь мы не используем токен UNK, потому что мы его специально не учили\n",
    "        # становится непонятно какой же эмбеддинг присвоить неизвестному слову,\n",
    "        # поэтому просто выбрасываем наши неизветсные слова\n",
    "        \n",
    "        return [self.word2index[word]  if word in self.word2index else self.word2index['UNK'] for word in tokenized_text]\n",
    "    \n",
    "    def padding(self, sequence):\n",
    "        \n",
    "        # Ограничить длину self.sequence_length\n",
    "        # если длина меньше максимально - западить\n",
    "        if len(sequence)< self.sequence_length:\n",
    "          add_pad = self.sequence_length - len(sequence)\n",
    "          return sequence+[self.pad_index]*add_pad\n",
    "        else:\n",
    "          return sequence[:self.sequence_length]\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        x = self.x_data[idx]\n",
    "        x = self.padding(x)\n",
    "        x = torch.Tensor(x).long()\n",
    "        \n",
    "        y = self.y_data[idx]\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "R3WW8V9lyLm0"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "Lnc2nD8gW-Br",
    "outputId": "d72654f9-7a85-49a6-e0c2-429b5db04c4e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|███████████████████████████████████| 18784/18784 [00:08<00:00, 2343.92it/s]\n",
      "Loading data: 100%|█████████████████████████████████████| 4697/4697 [00:01<00:00, 2948.74it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train, x_validation, y_train, y_validation = train_test_split(data.text, data.subject, test_size=0.2)\n",
    "\n",
    "train_dataset = WordData(list(x_train), list(y_train), word2index)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16)\n",
    "\n",
    "validation_dataset = WordData(list(x_validation), list(y_validation), word2index)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zy0dkkTIW-Bw"
   },
   "source": [
    "# Эксперименты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "3wwkxZm1vE43"
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "class model_clstm(torch.nn.Module):\n",
    "    def __init__(self, matrix_w, n, conv_out=150, conv_window=[2, 3, 4],\n",
    "                 dropout = 0.5,  output_dim=6, lstm_memory_dim=150,\n",
    "                 dropout_locate='lstm', max_length=512): #n - количетсво категорий\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.n = n\n",
    "        self.embedding_dim = matrix_w.shape[1]\n",
    "        #self.hidden_size = hidden_size\n",
    "        self.conv_out = conv_out\n",
    "        self.conv_window = conv_window\n",
    "        self.max_cnn_res = max_length - max(conv_window) + 1\n",
    "        self.lstm_memory_dim = lstm_memory_dim\n",
    "        self.dropout = dropout\n",
    "        self.dropout_locate = dropout_locate\n",
    "        \n",
    "        self.emb_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix_w))\n",
    "        conv_layers = []\n",
    "        for c in conv_window:\n",
    "            conv_layers.append(torch.nn.Conv1d(self.embedding_dim, self.conv_out, kernel_size=(c,), padding='valid'))\n",
    "        self.convs = torch.nn.ModuleList(conv_layers)\n",
    "\n",
    "        \n",
    "        self.LSTM = torch.nn.LSTM(input_size=self.conv_out * len(self.conv_window), \n",
    "                                  hidden_size=self.lstm_memory_dim,\n",
    "                                  num_layers=1, batch_first=True)\n",
    "        \n",
    "        self.soft = torch.nn.Softmax(dim=1)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.linear = torch.nn.Linear(in_features=self.lstm_memory_dim,\n",
    "                                out_features=self.n)\n",
    "        self.dropout = torch.nn.Dropout(p=0.5)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        if self.dropout_locate == 'cnn':\n",
    "            x_emb = self.emb_layer(x)\n",
    "        else:\n",
    "            x_emb = self.dropout(self.emb_layer(x))\n",
    "            \n",
    "        x_emb = x_emb.transpose(1,2)\n",
    "        \n",
    "        cnn_results = []\n",
    "        for conv in self.convs:\n",
    "            cnn_res = self.relu(conv(x_emb))[:, :, :self.max_cnn_res]\n",
    "            cnn_results.append(cnn_res)\n",
    "            \n",
    "        if len(self.conv_window) > 1:\n",
    "            to_lstm = torch.cat(cnn_results, 1)\n",
    "        else:\n",
    "            to_lstm = cnn_res\n",
    "            \n",
    "        to_lstm = to_lstm.transpose(1, 2)\n",
    "        _, (x, _)= self.LSTM(to_lstm)\n",
    "        x.squeeze_(0)\n",
    "        \n",
    "        if self.dropout_locate != 'cnn':           \n",
    "            x = self.dropout(x)\n",
    "        logits = self.soft(self.linear(x))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "7rUTc0l60pV9",
    "outputId": "ea81b9b3-b1d3-4122-869b-da0592397d76"
   },
   "outputs": [],
   "source": [
    "def train_val(model_clstm, train_loader=train_loader, validation_loader=validation_loader):\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.RMSprop(params=model_clstm.parameters(), lr=0.001, weight_decay=0.001)\n",
    "\n",
    "    model_clstm = model_clstm.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "    epochs = 5\n",
    "    losses = []\n",
    "    best_test_loss = 10\n",
    "\n",
    "    test_accuracy = []\n",
    "\n",
    "    for n_epoch in range(epochs):\n",
    "\n",
    "        train_losses = []\n",
    "        test_losses = []\n",
    "        test_targets = []\n",
    "        test_pred_class = []\n",
    "\n",
    "        progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
    "\n",
    "        model_clstm.train()\n",
    "\n",
    "        for x, y in train_loader:\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred = model_clstm(x)\n",
    "            loss = criterion(pred, y)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n",
    "\n",
    "            progress_bar.update(x.shape[0])\n",
    "\n",
    "        progress_bar.close()\n",
    "\n",
    "        model_clstm.eval()\n",
    "\n",
    "        for x, y in validation_loader:\n",
    "\n",
    "            x = x.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                pred = model_clstm(x)\n",
    "\n",
    "                pred = pred.cpu()\n",
    "\n",
    "                test_targets.append(y.numpy())\n",
    "                test_pred_class.append(np.argmax(pred, axis=1))\n",
    "\n",
    "                loss = criterion(pred, y)\n",
    "\n",
    "                test_losses.append(loss.item())\n",
    "\n",
    "        mean_test_loss = np.mean(test_losses)\n",
    "\n",
    "        test_targets = np.concatenate(test_targets).squeeze()\n",
    "        test_pred_class = np.concatenate(test_pred_class).squeeze()\n",
    "\n",
    "        accuracy = accuracy_score(test_targets, test_pred_class)\n",
    "\n",
    "        test_accuracy.append(accuracy)\n",
    "\n",
    "        print()\n",
    "        print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
    "\n",
    "        print('Accuracy test - {:.3f}'.format(accuracy))\n",
    "\n",
    "        # Early stopping:\n",
    "        #if mean_test_loss < best_test_loss:\n",
    "        #    best_test_loss = mean_test_loss\n",
    "        #else:\n",
    "        #    print('Early stopping')\n",
    "        #    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Эксперимент номер один"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clstm = model_clstm(vectors, 6, conv_window=[3, 4], dropout_locate='cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_clstm(\n",
       "  (emb_layer): Embedding(95415, 300)\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv1d(300, 150, kernel_size=(3,), stride=(1,), padding=valid)\n",
       "    (1): Conv1d(300, 150, kernel_size=(4,), stride=(1,), padding=valid)\n",
       "  )\n",
       "  (LSTM): LSTM(300, 150, batch_first=True)\n",
       "  (soft): Softmax(dim=1)\n",
       "  (relu): ReLU()\n",
       "  (linear): Linear(in_features=150, out_features=6, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_clstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "bL6zIZSt0h9W"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Vsxw4M2m0m2B"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|████████████████████████| 18784/18784 [01:34<00:00, 198.64it/s, train_loss=1.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 1.591, test - 1.550\n",
      "Accuracy test - 0.493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|████████████████████████| 18784/18784 [01:26<00:00, 216.64it/s, train_loss=1.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 1.543, test - 1.519\n",
      "Accuracy test - 0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|████████████████████████| 18784/18784 [01:30<00:00, 206.58it/s, train_loss=1.46]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 1.507, test - 1.439\n",
      "Accuracy test - 0.604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|████████████████████████| 18784/18784 [01:28<00:00, 211.66it/s, train_loss=1.45]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 1.451, test - 1.433\n",
      "Accuracy test - 0.609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|████████████████████████| 18784/18784 [01:28<00:00, 211.16it/s, train_loss=1.45]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 1.449, test - 1.445\n",
      "Accuracy test - 0.597\n"
     ]
    }
   ],
   "source": [
    "train_val(model_clstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уже лучше, хотя начинает переобучаться -- 0.609"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1TMaPbh3oWwc"
   },
   "source": [
    "Если вы запускаете много раз колаб окна и ткдм начинает беситься, можно запустить окно ниже, ткдм обновится и все снова станет хорошо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "_aPjTQcR0vm2",
    "outputId": "03d584f8-2f8c-4e0b-ae8e-7112f6624275"
   },
   "outputs": [],
   "source": [
    "for instance in list(tqdm._instances): \n",
    "    tqdm._decr_instances(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "QuesT_Homework3_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
